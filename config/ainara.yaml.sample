# Ainara Configuration File

# Speech-to-Text configuration
stt:
  # Default input module to use
  default_module: "custom"
  # Available modules:
  # - whisper: High-quality speech recognition using llama.cpp whisper
  backend: "faster_whisper"
  modules:
    whisper:
      # Service to use for Whisper transcription
      # Available services: openai, custom
      service: "custom"
      language: "en"

      # OpenAI service settings
      openai:
        api_key: "<YOUR-OPENAI-API-KEY>"
        api_url: "https://api.openai.com/v1/audio/transcriptions"
        model: "whisper-1"

      # Custom service settings (for alternative Whisper API providers)
      custom:
        api_key: "<YOUR-API-KEY>"
        api_url: "http://127.0.0.1:8080/inference"
        model: "whisper-1"
        # Additional headers if needed
        headers: {}

# Text-to-Speech configuration
tts:
  # Default output module to use
  default_module: "piper"
  # Available modules:
  # - piper: High-quality neural TTS using Piper
  modules:
    piper:
      binary: "/usr/bin/piper-tts"
      # model: "~/lab/llm/piper/es_MX-claude-14947-epoch-high.onnx"
      options: "--output_raw --length_scale 0.7"  # Optional: for raw audio output
      model: "~/lab/llm/piper/en_US-amy-medium.onnx"
      # model: "~/lab/llm/piper/en_US-ljspeech-high.onnx"


# LLM configuration
llm:
  # Default backend to use
  backend: "litellm"
  # List of LLM providers in order of preference
  providers:
    #- model: "openai/gamingpc"
    #  api_base: "http://192.168.1.200:7080"
    #  api_key: "nokey"
    # - model: "fireworks_ai/accounts/fireworks/models/deepseek-v3"
    #   api_key: "<key>"
    - model: "openrouter/deepseek/deepseek-chat-v3-0324"
      api_key: "<key>"
    # - model: "openrouter/deepseek/deepseek-r1"
    #   api_key: "<key>"
    # - model: "openai/gamingpc"
    #   api_base: "http://127.0.0.1:7080"
    #   api_key: "nokey"
  model_contexts:
    "openai/gamingpc": 16384
    # "openai/gamingpc": 2048
    # accounts/fireworks/models/llama-v3p3-70b-instruct: 131072

# Ainara configuration
orakle:
  # List of Orakle API servers in order of preference
  servers:
    - "http://127.0.0.1:5000"
    - "http://192.168.1.200:5000"

apis:
  finance:
    alphavantage_api_key: "<key>"

  search:
    google:
      api_key: "<key>"
      cx: "<key>"
    tavily:
      api_key: "<key>"
    perplexity:
      api_key: "<key>"
    metaphor:
      api_key: "<key>"
    newsapi:
      api_key: "<key>"

  twitter:
    api_key: "<key>"
    api_secret: "<key>"
    bearer_token: "<key>"
    access_token: "<key>"
    access_token_secret: "<key>"

  reddit:
    client_id: "YOUR-REDDIT-CLIENT-ID"
    client_secret: "YOUR-REDDIT-CLIENT-SECRET"

  weather:
    openweathermap_api_key: "<key>"

  crypto:
    coinmarketcap_api_key: "<key>"

  helius:
    api_key: "<key>"


# Memory configuration
memory:
  enabled: false
  # Default context to use when none is provided
  default_context:
    persona: "default"

  # Text storage configuration
  text_storage:
    # Backend type (sqlite, etc.)
    type: "sqlite"
    # Storage path for the database
    storage_path: "~/.cache/ainara/chat_memory.db"

  # Vector storage configuration
  vector_storage:
    # Enable/disable vector storage
    enabled: true
    # Backend type (chroma, etc.)
    type: "chroma"
    # Storage path for vector database
    storage_path: "~/.cache/ainara/vector_db"
    # Embedding model to use
    embedding_model: "sentence-transformers/all-mpnet-base-v2"

services:
  venvPath: "/home/ruben/lab/src/ainara/venv"
